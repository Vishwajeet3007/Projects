# ğŸ’¬ LangGraph + Gemini AI Chatbot (Streamlit)

This project is a simple **chatbot** built using [LangGraph](https://github.com/langchain-ai/langgraph), Google's **Gemini AI**, and **Streamlit**. It demonstrates a lightweight conversational app using **state graphs** to manage messages and memory, powered by **LangChain** and Geminiâ€™s `langchain-google-genai` integration.

---

## ğŸš€ Features

- ğŸ” **Stateful chat flow** using LangGraph
- ğŸ¤– **LLM-powered responses** with Gemini 1.5 Flash/Pro
- ğŸ“¦ **In-memory checkpointing** (for simplicity)
- ğŸ§  **LangChain-compatible** message handling
- ğŸ–¥ï¸ **Streamlit frontend** with persistent conversation history
- ğŸ¯ **Modular code structure** (clean separation of backend and frontend)

---

## ğŸ“¸ Chatbot Demo

Hereâ€™s a quick preview of the working chatbot UI:

<p align="center">
  <img src="../ChatBot_In_LangGraph/ChatBot_OUTPUT.jpg" alt="Chatbot Demo" width="600"/>
</p>

---

## ğŸ—‚ï¸ Project Structure

```bash
ChatBot_In_LangGraph/
â”œâ”€â”€ .env                  # API keys and environment variables
â”œâ”€â”€ backend.py            # LangGraph state machine + Gemini config
â”œâ”€â”€ streamlit_frontend.py # Streamlit UI code
â”œâ”€â”€ requirements.txt      # Project dependencies
â”œâ”€â”€ ChatBot_OUTPUT.jpg    # Output screenshot (demo)
â””â”€â”€ README.md             # Project overview
ğŸ§  How It Works
ğŸ’¬ User inputs a message via Streamlit chat UI

ğŸ›  Message is passed to the LangGraph state machine

ğŸŒ Gemini 1.5 Flash generates a response

ğŸ“¤ Response is streamed back and rendered live in the UI

ğŸ” Conversation is preserved using st.session_state

